# Real-time Audio Transcription with VAD

Проект для записи аудио и транскрипции в реальном времени с использованием продвинутого VAD (Voice Activity Detection), который предотвращает обрывы на пол-слова.

## Возможности

- Запись аудио с микрофона в реальном времени
- Продвинутый VAD на основе Silero VAD
- Буферизация для предотвращения обрывов на пол-слова
- Транскрипция через локальный Whisper (faster-whisper)
- Опциональная обработка транскрипций через LLM (OpenAI API или локальный Ollama)
- CLI интерфейс для простого использования

## Установка

1. Установите зависимости:

```bash
pip install -r requirements.txt
```

2. При первом запуске Whisper автоматически загрузит выбранную модель.

## Использование

Базовое использование:

```bash
python -m app.main
```

С параметрами:

```bash
python -m app.main --trsc-model-size base --trsc-language ru --trsc-post-speech-buffer-ms 500
```

### Параметры транскрипции

- `--sample-rate`: Частота дискретизации аудио (по умолчанию: 16000)
- `--trsc-model-size`: Размер модели Whisper - tiny, base, small, medium, large (по умолчанию: medium)
- `--trsc-device`: Устройство для обработки - cpu или cuda (по умолчанию: cpu)
- `--trsc-language`: Код языка (например, 'en', 'ru'). None для автоопределения
- `--trsc-pre-speech-buffer-ms`: Буфер перед началом речи в миллисекундах (по умолчанию: 300)
- `--trsc-post-speech-buffer-ms`: Буфер после окончания речи для предотвращения обрывов (по умолчанию: 500)
- `--trsc-max-speech-duration-ms`: Максимальная длительность речи в миллисекундах перед принудительным прерыванием (по умолчанию: 15000 = 15 секунд)
- `--trsc-initial-prompt`: Начальный промпт для улучшения качества транскрипции (по умолчанию: "Это разговор о программировании.")

### Параметры LLM (опционально)

- `--llm`: Включить обработку транскрипций через LLM (по умолчанию: отключено)
- `--llm-base-url`: Базовый URL для LLM API (по умолчанию: http://localhost:11434/v1 для Ollama)
- `--llm-key`: API ключ (требуется для OpenAI, опционально для локального Ollama)
- `--llm-model`: Название модели LLM (по умолчанию: llama3 для Ollama)
- `--llm-temperature`: Температура для генерации (по умолчанию: 0.7)
- `--llm-max-tokens`: Максимальное количество токенов в ответе (по умолчанию: 500)
- `--llm-init-prompt`: Начальный системный промпт для LLM (по умолчанию: пусто)

## Как это работает

1. **Запись аудио**: Модуль `AudioRecorder` записывает аудио с микрофона в реальном времени
2. **VAD обработка**: `VoiceActivityDetector` анализирует аудио и определяет активность речи
3. **Буферизация**: Система сохраняет аудио до и после речи для предотвращения обрывов
4. **Транскрипция**: Завершенные сегменты речи транскрибируются через Whisper
5. **Обработка LLM** (опционально): Транскрипции могут быть обработаны через LLM для дополнительного анализа
6. **Вывод**: Результаты транскрипции и ответы LLM выводятся в консоль в реальном времени

## Структура проекта

```
interview/
├── app/
│   ├── audio/
│   │   ├── recorder.py          # Запись аудио
│   │   └── audio_processor.py   # Обработка аудио
│   ├── vad/
│   │   └── voice_activity_detector.py  # VAD с буферизацией
│   ├── transcription/
│   │   └── whisper_transcriber.py      # Транскрипция
│   ├── llm/
│   │   └── llm_client.py               # Клиент для LLM API
│   └── main.py                   # CLI приложение
├── requirements.txt
└── README.md
```

## Остановка

Нажмите `Ctrl+C` для остановки записи и транскрипции.

